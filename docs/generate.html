<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Text Generation &#8212; phi-3-vision-mlx 0.0.8-alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=57b72bbe" />
    <script src="_static/documentation_options.js?v=0c1e2857"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="LoRA Fine-tuning" href="train.html" />
    <link rel="prev" title="Installation" href="install.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">phi-3-vision-mlx</a></h1>



<p class="blurb">A versatile AI framework leveraging Phi-3-Vision and Phi-3-Mini-128K models.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=JosefAlbers&repo=Phi-3-Vision-MLX&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#visual-question-answering">Visual Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#batch-text-generation">Batch Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-and-cache-quantization">Model and Cache Quantization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="train.html">LoRA Fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="agent.html">Agent Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="toolchain.html">Custom Toolchains</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="module.html">Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="module.html#functions">Functions</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="install.html" title="previous chapter">Installation</a></li>
      <li>Next: <a href="train.html" title="next chapter">LoRA Fine-tuning</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="text-generation">
<h1>Text Generation<a class="headerlink" href="#text-generation" title="Link to this heading">¶</a></h1>
<section id="visual-question-answering">
<h2>Visual Question Answering<a class="headerlink" href="#visual-question-answering" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;What is shown in this image?&#39;</span><span class="p">,</span> <span class="s1">&#39;https://collectionapi.metmuseum.org/api/collection/v1/iiif/344291/725918/main-image&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="batch-text-generation">
<h2>Batch Text Generation<a class="headerlink" href="#batch-text-generation" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Explain the key concepts of quantum computing and provide a Rust code example demonstrating quantum superposition.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Write a poem about the first snowfall of the year.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Summarize the major events of the French Revolution.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Describe a bustling alien marketplace on a distant planet with unique goods and creatures.&quot;</span>
    <span class="s2">&quot;Implement a basic encryption algorithm in Python.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Generate responses using Phi-3-Vision (multimodal model)</span>
<span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Generate responses using Phi-3-Mini-128K (language-only model)</span>
<span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">blind_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-and-cache-quantization">
<h2>Model and Cache Quantization<a class="headerlink" href="#model-and-cache-quantization" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model quantization</span>
<span class="n">generate</span><span class="p">(</span><span class="s2">&quot;Describe the water cycle.&quot;</span><span class="p">,</span> <span class="n">quantize_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Cache quantization</span>
<span class="n">generate</span><span class="p">(</span><span class="s2">&quot;Explain quantum computing.&quot;</span><span class="p">,</span> <span class="n">quantize_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &#169;2024, Josef Albers.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/generate.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/JosefAlbers/Phi-3-Vision-MLX" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>