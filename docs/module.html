<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Classes &#8212; phi-3-vision-mlx 0.0.8-alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=57b72bbe" />
    <script src="_static/documentation_options.js?v=0c1e2857"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Benchmark" href="benchmark.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">phi-3-vision-mlx</a></h1>



<p class="blurb">A versatile AI framework leveraging Phi-3-Vision and Phi-3-Mini-128K models.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=JosefAlbers&repo=Phi-3-Vision-MLX&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="generate.html">Text Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">LoRA Fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="agent.html">Agent Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="toolchain.html">Custom Toolchains</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="#functions">Functions</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="benchmark.html" title="previous chapter">Benchmark</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="classes">
<h1>Classes<a class="headerlink" href="#classes" title="Link to this heading">¶</a></h1>
<section id="agent">
<h2>Agent<a class="headerlink" href="#agent" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="phi_3_vision_mlx.Agent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">Agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">toolchain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_api</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.Agent" title="Link to this definition">¶</a></dt>
<dd><p>A flexible agent class for managing toolchains and executing prompts.</p>
<p>The Agent class provides a framework for processing prompts through a series of tools
(functions) defined in a toolchain. It manages the execution flow, handles input and output,
and maintains a log of operations.</p>
<section id="attributes">
<h3>Attributes:<a class="headerlink" href="#attributes" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>_default_toolchain<span class="classifier">str</span></dt><dd><p>A string defining the default toolchain, which includes adding code to prompts,
generating responses, and executing code.</p>
</dd>
</dl>
</section>
<section id="methods">
<h3>Methods:<a class="headerlink" href="#methods" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>__init__(self, toolchain=None, enable_api=True, <a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs)</dt><dd><p>Initialize the Agent with a toolchain and other optional parameters.</p>
</dd>
<dt>__call__(self, prompt:str, images=None)</dt><dd><p>Process a given prompt (and optionally images) through the toolchain.</p>
</dd>
<dt>reset()</dt><dd><p>Reset the agent’s log and ongoing operations.</p>
</dd>
<dt>log_step()</dt><dd><p>Log the current step of operations.</p>
</dd>
<dt>end()</dt><dd><p>End the current session, log the final step, and reset the agent.</p>
</dd>
<dt>set_toolchain(s)</dt><dd><p>Set a new toolchain for the agent to use.</p>
</dd>
</dl>
</section>
<section id="usage">
<h3>Usage:<a class="headerlink" href="#usage" title="Link to this heading">¶</a></h3>
<p>The Agent can be used to process prompts through a defined series of operations:
1. Initialize an Agent with a custom toolchain or use the default.
2. Call the Agent with a prompt (and optionally images) to process.
3. The Agent will execute each tool in the toolchain, passing results between steps.
4. Results are logged at each step and can be accessed or saved.</p>
<p>The toolchain is a string defining a series of operations, where each line is of the form:
‘output1, output2, … = function_name(input1, input2, …)’</p>
</section>
<section id="example">
<h3>Example:<a class="headerlink" href="#example" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">agent</span><span class="p">(</span><span class="s2">&quot;Tell me about this image&quot;</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;path/to/image.jpg&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;responses&#39;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="notes">
<h3>Notes:<a class="headerlink" href="#notes" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>The Agent supports API input handling, which can be enabled/disabled during initialization.</p></li>
<li><p>The toolchain can be customized to include different functions and processing steps.</p></li>
<li><p>The Agent maintains a log of all operations, which can be useful for debugging or analysis.</p></li>
<li><p>The ‘enable_api’ parameter affects how the Agent handles quotation marks in prompts.</p></li>
</ul>
</section>
</dd></dl>

</section>
</section>
<section id="functions">
<h1>Functions<a class="headerlink" href="#functions" title="Link to this heading">¶</a></h1>
<section id="load">
<h2>load<a class="headerlink" href="#load" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.load">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">blind_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adapter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.load" title="Link to this definition">¶</a></dt>
<dd><p>Load a Phi-3 model with specified configuration.</p>
<section id="parameters">
<h3>Parameters:<a class="headerlink" href="#parameters" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>blind_model<span class="classifier">bool, optional</span></dt><dd><p>If True, load the language-only model. If False, load the vision model. Default is False.</p>
</dd>
<dt>quantize_model<span class="classifier">bool, optional</span></dt><dd><p>If True, load the quantized version of the model. Default is False.</p>
</dd>
<dt>quantize_cache<span class="classifier">bool, optional</span></dt><dd><p>If True, use quantized cache for the model. Default is False.</p>
</dd>
<dt>use_adapter<span class="classifier">bool, optional</span></dt><dd><p>If True, load and use a LoRA adapter for the model. Default is False.</p>
</dd>
<dt><a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs<span class="classifier">dict</span></dt><dd><p>Additional keyword arguments to pass to the model loading function.</p>
</dd>
</dl>
</section>
<section id="returns">
<h3>Returns:<a class="headerlink" href="#returns" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>tuple</dt><dd><p>A tuple containing the loaded model and processor.</p>
</dd>
</dl>
</section>
<section id="id5">
<h3>Notes:<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>If the model path doesn’t exist, it will call _setup() to download or prepare the model.</p></li>
<li><p>The function uses predefined paths (PATH_*) to locate model files.</p></li>
</ul>
</section>
</dd></dl>

</section>
<section id="generate">
<h2>generate<a class="headerlink" href="#generate" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.generate">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preload</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blind_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adapter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_tps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_chat_template</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.generate" title="Link to this definition">¶</a></dt>
<dd><p>Generate text based on a given prompt, optionally with image input.</p>
<section id="id6">
<h3>Parameters:<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>prompt<span class="classifier">str</span></dt><dd><p>The input prompt for text generation.</p>
</dd>
<dt>images<span class="classifier">list of str or None, optional</span></dt><dd><p>List of image paths or URLs to process along with the prompt.</p>
</dd>
<dt>preload<span class="classifier">tuple or None, optional</span></dt><dd><p>A pre-loaded model and processor tuple. If None, a model will be loaded.</p>
</dd>
<dt>blind_model<span class="classifier">bool, optional</span></dt><dd><p>If True, use the language-only model. Default is False.</p>
</dd>
<dt>quantize_model<span class="classifier">bool, optional</span></dt><dd><p>If True, use the quantized version of the model. Default is False.</p>
</dd>
<dt>quantize_cache<span class="classifier">bool, optional</span></dt><dd><p>If True, use quantized cache for the model. Default is False.</p>
</dd>
<dt>use_adapter<span class="classifier">bool, optional</span></dt><dd><p>If True, use a LoRA adapter with the model. Default is False.</p>
</dd>
<dt>max_tokens<span class="classifier">int, optional</span></dt><dd><p>Maximum number of tokens to generate. Default is 1000.</p>
</dd>
<dt>verbose<span class="classifier">bool, optional</span></dt><dd><p>If True, print additional information during generation. Default is True.</p>
</dd>
<dt>return_tps<span class="classifier">bool, optional</span></dt><dd><p>If True, return tokens per second information. Default is False.</p>
</dd>
<dt>early_stop<span class="classifier">bool or int, optional</span></dt><dd><p>If True or an integer, stop generation early under certain conditions.</p>
</dd>
<dt>stream<span class="classifier">bool, optional</span></dt><dd><p>If True, stream the generated text. Default is True.</p>
</dd>
<dt>apply_chat_template<span class="classifier">bool, optional</span></dt><dd><p>If True, apply a chat template to the prompt. Default is True.</p>
</dd>
</dl>
</section>
<section id="id7">
<h3>Returns:<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>str or tuple</dt><dd><p>Generated text, or a tuple containing generated text and additional information
if return_tps is True.</p>
</dd>
</dl>
</section>
<section id="id8">
<h3>Notes:<a class="headerlink" href="#id8" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>If ‘&lt;<a href="#id35"><span class="problematic" id="id36">|api_input|</span></a>&gt;’ is in the prompt, it will call get_api() instead.</p></li>
<li><p>The function can handle both text-only and text-image inputs.</p></li>
</ul>
</section>
</dd></dl>

</section>
<section id="constrain">
<h2>constrain<a class="headerlink" href="#constrain" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.constrain">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">constrain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[(30,</span> <span class="pre">'</span> <span class="pre">The</span> <span class="pre">correct</span> <span class="pre">answer</span> <span class="pre">is'),</span> <span class="pre">(10,</span> <span class="pre">'X.')]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preload</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blind_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adapter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_chat_template</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.constrain" title="Link to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Perform constrained decoding on the given prompt using specified constraints.</p>
<dl class="simple">
<dt>prompt<span class="classifier">str or list of str</span></dt><dd><p>The input prompt(s) for text generation.</p>
</dd>
<dt>constraints<span class="classifier">list of tuples, optional</span></dt><dd><p>List of constraints in the format [(max_tokens, constraint_text), …].
Each constraint specifies the maximum number of tokens to generate before the constraint_text
must appear. Defaults to [(30, ‘ The correct answer is’), (10, ‘X.’)].</p>
</dd>
<dt>images<span class="classifier">list or None, optional</span></dt><dd><p>List of image inputs for multimodal models. Defaults to None.</p>
</dd>
<dt>preload<span class="classifier">tuple, optional</span></dt><dd><p>A tuple containing (model, processor) if already loaded. If None, the function will load
the model and processor based on the provided configuration. Defaults to None.</p>
</dd>
<dt>blind_model<span class="classifier">bool, optional</span></dt><dd><p>If True, uses a model without vision capabilities. Defaults to False.</p>
</dd>
<dt>quantize_model<span class="classifier">bool, optional</span></dt><dd><p>If True, uses a quantized version of the model. Defaults to False.</p>
</dd>
<dt>quantize_cache<span class="classifier">bool, optional</span></dt><dd><p>If True, uses cache quantization. Defaults to False.</p>
</dd>
<dt>use_adapter<span class="classifier">bool, optional</span></dt><dd><p>If True, uses a LoRA adapter with the model. Defaults to False.</p>
</dd>
<dt>apply_chat_template<span class="classifier">bool, optional</span></dt><dd><p>If True, applies a chat template to the prompt before processing. Defaults to True.</p>
</dd>
</dl>
<dl class="simple">
<dt>str or list of str</dt><dd><p>The generated text(s) adhering to the specified constraints. Returns a single string if
the input prompt was a string, otherwise returns a list of strings.</p>
</dd>
</dl>
<ul class="simple">
<li><p>The function preprocesses the prompt and applies the constraints sequentially.</p></li>
<li><p>It uses a custom constrained generation algorithm to ensure the output adheres to the constraints.</p></li>
<li><p>The output format matches the input format (str or list of str).</p></li>
<li><p>If apply_chat_template is True, the prompt is processed through a chat template before generation.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Write a Python function to calculate the Fibonacci sequence up to a given number n.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;</span>
</pre></div>
</div>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">&quot;),</span> <span class="pre">(100,</span> <span class="pre">&quot;</span> <span class="pre">return</span> <span class="pre">&quot;),</span> <span class="pre">(100,</span> <span class="pre">&quot;</span>
<span class="pre">`</span></code>”)]</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constrain</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="execute">
<h2>execute<a class="headerlink" href="#execute" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.execute">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">execute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">code_strings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.execute" title="Link to this definition">¶</a></dt>
<dd><p>Execute one or more Python code strings and capture the results.</p>
<section id="id9">
<h3>Parameters:<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>code_strings<span class="classifier">str or list of str</span></dt><dd><p>A single code string or a list of code strings to execute.</p>
</dd>
<dt>file_prefix<span class="classifier">int or str, optional</span></dt><dd><p>A prefix to use for naming output files. Default is 0.</p>
</dd>
<dt>verbose<span class="classifier">bool, optional</span></dt><dd><p>If True, print execution results. Default is True.</p>
</dd>
</dl>
</section>
<section id="id10">
<h3>Returns:<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>dict</dt><dd><p>A dictionary containing lists of execution results:
- ‘codes’: The input code strings
- ‘files’: Names of any files generated during execution
- ‘souts’: Standard output from each execution
- ‘serrs’: Standard error from each execution</p>
</dd>
</dl>
</section>
<section id="id11">
<h3>Notes:<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Each code string is executed in a separate environment.</p></li>
<li><p>The function captures standard output, standard error, and any generated files.</p></li>
<li><p>If verbose is True, execution results are printed to the console.</p></li>
</ul>
</section>
</dd></dl>

</section>
<section id="train-lora">
<h2>train_lora<a class="headerlink" href="#train-lora" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.train_lora">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">train_lora</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'models/phi3_mini_128k_Q'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora_targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['self_attn.qkv_proj',</span> <span class="pre">'self_attn.o_proj']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora_rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">take</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'JosefAlbers/akemiH_MedQA_Reason'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.train_lora" title="Link to this definition">¶</a></dt>
<dd><p>Train a LoRA (Low-Rank Adaptation) model using the specified parameters.</p>
<p>This function loads a pre-trained model, applies LoRA adaptations, and fine-tunes it on a given dataset.
It supports various training configurations, including masking strategies and learning rate scheduling.</p>
<section id="id12">
<h3>Parameters:<a class="headerlink" href="#id12" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>model_path<span class="classifier">str, optional</span></dt><dd><p>Path to the base model. Defaults to PATH_QUANTIZED_PHI3_BLIND.</p>
</dd>
<dt>adapter_path<span class="classifier">str or None, optional</span></dt><dd><p>Path to save the LoRA adapter. If None, it’s set to ‘{PATH_ADAPTERS}/{model_path}’.
Defaults to None.</p>
</dd>
<dt>lora_layers<span class="classifier">int, optional</span></dt><dd><p>Number of layers to apply LoRA. Defaults to 1.</p>
</dd>
<dt>lora_rank<span class="classifier">int, optional</span></dt><dd><p>Rank of the LoRA adapter. Defaults to 1.</p>
</dd>
<dt>epochs<span class="classifier">int, optional</span></dt><dd><p>Number of training epochs. Defaults to 1.</p>
</dd>
<dt>batch_size<span class="classifier">int, optional</span></dt><dd><p>Batch size for training. Defaults to 1.</p>
</dd>
<dt>take<span class="classifier">int, optional</span></dt><dd><p>Number of samples to take from the dataset. Defaults to 10.</p>
</dd>
<dt>lr<span class="classifier">float, optional</span></dt><dd><p>Learning rate for the optimizer. Defaults to 1e-4.</p>
</dd>
<dt>warmup<span class="classifier">float, optional</span></dt><dd><p>Fraction of total steps to use for learning rate warmup. Defaults to 0.5.</p>
</dd>
<dt>mask_ratios<span class="classifier">list of float or None, optional</span></dt><dd><p>Ratios for input masking. If None, no masking is applied. Defaults to None.</p>
</dd>
<dt>dataset_path<span class="classifier">str, optional</span></dt><dd><p>Path to the dataset used for training. Defaults to “JosefAlbers/akemiH_MedQA_Reason”.</p>
</dd>
</dl>
</section>
<section id="id13">
<h3>Returns:<a class="headerlink" href="#id13" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>None</dt><dd><p>The function doesn’t return a value but saves the trained LoRA adapter to the specified path.</p>
</dd>
</dl>
</section>
<section id="id14">
<h3>Notes:<a class="headerlink" href="#id14" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>The function uses several helper methods for data processing, loss calculation, and training.</p></li>
<li><p>It applies a learning rate schedule with warmup.</p></li>
<li><p>If mask_ratios are provided, it applies input masking during training.</p></li>
<li><p>The function uses AdamW optimizer for training.</p></li>
<li><p>After training, it cleans up by deleting the model and processor to free memory.</p></li>
</ul>
</section>
<section id="id15">
<h3>Example:<a class="headerlink" href="#id15" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_lora</span><span class="p">(</span><span class="n">lora_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lora_rank</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">take</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">dataset_path</span><span class="o">=</span><span class="s2">&quot;JosefAlbers/akemiH_MedQA_Reason&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
<section id="test-lora">
<h2>test_lora<a class="headerlink" href="#test-lora" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.test_lora">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">test_lora</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'models/phi3_mini_128k_Q'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'JosefAlbers/akemiH_MedQA_Reason'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">take</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">10)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.test_lora" title="Link to this definition">¶</a></dt>
<dd><p>Test a LoRA (Low-Rank Adaptation) model on a given dataset using various generation methods.</p>
<p>This function loads a model and its LoRA adapter (if specified), processes a dataset, and evaluates
the model’s performance on recall (summarization) and answer generation tasks using different methods.</p>
<section id="id16">
<h3>Parameters:<a class="headerlink" href="#id16" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>model_path<span class="classifier">str, optional</span></dt><dd><p>Path to the base model. Defaults to PATH_QUANTIZED_PHI3_BLIND.</p>
</dd>
<dt>adapter_path<span class="classifier">bool or str, optional</span></dt><dd><p>Path to the LoRA adapter. If True, it’s set to ‘{PATH_ADAPTERS}/{model_path}’.
If None, the model without adapter is tested. Defaults to True.</p>
</dd>
<dt>dataset_path<span class="classifier">str, optional</span></dt><dd><p>Path to the dataset to be used for testing. Defaults to “JosefAlbers/akemiH_MedQA_Reason”.</p>
</dd>
<dt>take<span class="classifier">tuple of int, optional</span></dt><dd><p>Range of samples to take from the dataset, in the format (start, end). Defaults to (0, 10).</p>
</dd>
<dt>batch_size<span class="classifier">int, optional</span></dt><dd><p>Number of samples to process in each batch. Defaults to 10.</p>
</dd>
</dl>
</section>
<section id="id17">
<h3>Returns:<a class="headerlink" href="#id17" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>None</dt><dd><p>The function prints the evaluation results, including scores for different generation methods,
but doesn’t return any value.</p>
</dd>
</dl>
</section>
<section id="id18">
<h3>Notes:<a class="headerlink" href="#id18" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>It performs three tasks: recall of trained texts, answer generation using _choose_from(),
and answer generation using constrained decoding.</p></li>
<li><p>For recall, it generates a summary and compares it with the true summary.</p></li>
<li><p>For answer generation, it uses two methods:
1. _choose_from(): Chooses an answer from options A-E.
2. Constrained decoding: Generates an answer with specific constraints.</p></li>
<li><p>The function prints comparisons between generated and true responses for each task.</p></li>
<li><p>After completion, it prints scores for both answer generation methods.</p></li>
<li><p>The model and processor are deleted after use to free up memory.</p></li>
</ul>
</section>
<section id="id19">
<h3>Example:<a class="headerlink" href="#id19" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_lora</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;path/to/model&quot;</span><span class="p">,</span> <span class="n">adapter_path</span><span class="o">=</span><span class="s2">&quot;path/to/adapter&quot;</span><span class="p">,</span>
<span class="gp">... </span>          <span class="n">dataset_path</span><span class="o">=</span><span class="s2">&quot;dataset/path&quot;</span><span class="p">,</span> <span class="n">take</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
<section id="benchmark">
<h2>benchmark<a class="headerlink" href="#benchmark" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.benchmark">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">benchmark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">blind_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">json_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'benchmark.json'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.benchmark" title="Link to this definition">¶</a></dt>
<dd><p>Perform a benchmark test on different model configurations and save the results.</p>
<p>This function tests various configurations of a language model (vanilla, quantized model,
quantized cache, and LoRA) on a set of predefined prompts. It measures the performance
in terms of tokens per second (TPS) for both prompt processing and text generation.</p>
<section id="id20">
<h3>Parameters:<a class="headerlink" href="#id20" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>blind_model<span class="classifier">bool, optional</span></dt><dd><p>If True, uses a ‘blind’ version of the model (details depend on implementation).
Defaults to False.</p>
</dd>
</dl>
</section>
<section id="id21">
<h3>Returns:<a class="headerlink" href="#id21" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>None</dt><dd><p>The function doesn’t return a value but saves the benchmark results to a JSON file
and prints a formatted version of the results.</p>
</dd>
</dl>
</section>
<section id="behavior">
<h3>Behavior:<a class="headerlink" href="#behavior" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Defines a set of test prompts, including text-only and image-text prompts.</p></li>
<li><p>Tests four configurations: vanilla, quantized model, quantized cache, and LoRA.</p></li>
<li><p>For each configuration:
- Loads the model with appropriate settings.
- Processes each prompt and generates text.
- Measures TPS for prompt processing and text generation.</p></li>
<li><p>Saves all results to ‘benchmark.json’.</p></li>
<li><p>Calls a function to format and print the benchmark results.</p></li>
</ol>
</section>
<section id="id22">
<h3>Notes:<a class="headerlink" href="#id22" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>The function uses predefined prompts, including a mix of text-only and image-text tasks.</p></li>
<li><p>It generates 100 tokens for each prompt.</p></li>
<li><p>The results are stored in a dictionary with keys ‘vanilla’, ‘q_model’, ‘q_cache’, ‘lora’.</p></li>
<li><p>Each result entry contains the prompt index, prompt TPS, and generation TPS.</p></li>
<li><p>The function cleans up resources by deleting the model after each configuration test.</p></li>
<li><p>Requires ‘generate’, ‘load’, and ‘_format_benchmark’ functions to be defined elsewhere.</p></li>
</ul>
</section>
<section id="id23">
<h3>Example:<a class="headerlink" href="#id23" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">()</span>
<span class="go"># This will run the benchmark and save results to &#39;benchmark.json&#39;,</span>
<span class="go"># then print a formatted version of the results.</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">blind_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go"># Runs the benchmark using the &#39;blind&#39; version of the model (i.e., Phi-3-Mini-128K)</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
<section id="chat-ui">
<h2>chat_ui<a class="headerlink" href="#chat-ui" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.chat_ui">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">chat_ui</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">agent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.chat_ui" title="Link to this definition">¶</a></dt>
<dd><p>Create and launch a chat user interface using Gradio.</p>
<p>This function sets up an interactive chat interface that allows users to communicate with an AI agent.
It supports text input and file uploads (specifically images) and displays the conversation history.</p>
<p>This function is also the entry point for the ‘phi3v’ command-line tool, which can be run directly
from the terminal after installing the phi-3-vision-mlx package.</p>
<section id="id24">
<h3>Parameters:<a class="headerlink" href="#id24" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>agent<span class="classifier">Agent, optional</span></dt><dd><p>An instance of the Agent class to handle the chat logic. If None, a new Agent instance is created.
Default is None.</p>
</dd>
</dl>
</section>
<section id="id25">
<h3>Returns:<a class="headerlink" href="#id25" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>None</dt><dd><p>The function launches a Gradio interface and doesn’t return a value.</p>
</dd>
</dl>
</section>
<section id="id26">
<h3>Behavior:<a class="headerlink" href="#id26" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Initializes the chat agent if not provided.</p></li>
<li><p>Defines helper functions for message handling and bot responses:
- add_message: Adds user messages (text and files) to the chat history.
- bot: Processes user input through the agent and formats the response.
- reset: Resets the conversation and clears the chat history.</p></li>
<li><p>Creates a Gradio Blocks interface with the following components:
- Chatbot: Displays the conversation history.
- MultimodalTextbox: Allows text input and file uploads.
- Reset button: Clears the conversation.</p></li>
<li><p>Sets up event handlers for user input submission and bot responses.</p></li>
<li><p>Launches the Gradio interface in the browser.</p></li>
</ol>
</section>
<section id="id27">
<h3>Notes:<a class="headerlink" href="#id27" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>The interface supports both text and image inputs.</p></li>
<li><p>Bot responses are processed to remove ‘&lt;<a href="#id37"><span class="problematic" id="id38">|end|</span></a>&gt;’ tokens and empty lines.</p></li>
<li><p>The chat history keeps track of user inputs and bot responses, including file uploads.</p></li>
<li><p>The interface is set to occupy 80% of the viewport height.</p></li>
<li><p>The Gradio footer is hidden using custom CSS.</p></li>
<li><p>The interface is launched in-browser and inline.</p></li>
</ul>
</section>
<section id="dependencies">
<h3>Dependencies:<a class="headerlink" href="#dependencies" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Requires the Gradio library for creating the user interface.</p></li>
<li><p>Assumes the existence of an Agent class that handles the chat logic.</p></li>
</ul>
</section>
<section id="command-line-usage">
<h3>Command-line Usage:<a class="headerlink" href="#command-line-usage" title="Link to this heading">¶</a></h3>
<p>After installing the phi-3-vision-mlx package, you can run this function directly from the terminal using:</p>
<p>$ phi3v</p>
<p>This will launch the chat interface in your default web browser.</p>
</section>
<section id="id28">
<h3>Example:<a class="headerlink" href="#id28" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chat_ui</span><span class="p">()</span>
<span class="go"># This will launch the chat interface in the default web browser.</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">custom_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">custom_params</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chat_ui</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">custom_agent</span><span class="p">)</span>
<span class="go"># Launches the chat interface with a custom agent configuration.</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
<section id="get-api">
<h2>get_api<a class="headerlink" href="#get-api" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.get_api">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">get_api</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.get_api" title="Link to this definition">¶</a></dt>
<dd><p>Retrieve and format API code based on input prompts using vector similarity search.</p>
<p>This function uses a Vector Database (VDB) to find the most relevant API code
for given prompts. It’s designed to work with prompts that may contain the
‘&lt;<a href="#id39"><span class="problematic" id="id40">|api_input|</span></a>&gt;’ delimiter to separate the API request from additional input.</p>
<section id="id29">
<h3>Parameters:<a class="headerlink" href="#id29" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>prompt<span class="classifier">str or list of str</span></dt><dd><p>The input prompt(s) to search for relevant API code. If a prompt contains
‘&lt;<a href="#id41"><span class="problematic" id="id42">|api_input|</span></a>&gt;’, the part before it is used for the search, and the part
after it is used to format the retrieved code.</p>
</dd>
<dt>n_topk<span class="classifier">int, optional</span></dt><dd><p>The number of top matching API codes to retrieve for each prompt. Default is 1.</p>
</dd>
<dt>verbose<span class="classifier">bool, optional</span></dt><dd><p>If True, print the obtained API codes. Default is True.</p>
</dd>
</dl>
</section>
<section id="id30">
<h3>Returns:<a class="headerlink" href="#id30" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>list of str</dt><dd><p>A list of formatted API code strings relevant to the input prompt(s).</p>
</dd>
</dl>
</section>
<section id="id31">
<h3>Notes:<a class="headerlink" href="#id31" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>The function uses a VDB (Vector Database) for similarity search.</p></li>
<li><p>If multiple prompts are provided, it returns a list of API codes for each prompt.</p></li>
<li><p>The retrieved API code is formatted with the part of the prompt after ‘&lt;<a href="#id43"><span class="problematic" id="id44">|api_input|</span></a>&gt;’.</p></li>
<li><p>This function is typically used within an Agent’s toolchain for API-related tasks.</p></li>
</ul>
</section>
<section id="id32">
<h3>Example:<a class="headerlink" href="#id32" title="Link to this heading">¶</a></h3>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">toolchain</span><span class="o">=</span><span class="s2">&quot;responses = get_api(prompt)&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="p">(</span><span class="s1">&#39;Draw &lt;|api_input|&gt; A perfectly red apple, 32k HDR, studio lighting&#39;</span><span class="p">)</span>
<span class="go"># This will retrieve and format API code for image generation based on the given prompt.</span>
</pre></div>
</div>
<p>In this example, ‘Draw’ is used for the API search, and ‘A perfectly red apple, 32k HDR,
studio lighting’ is used to format the retrieved API code.</p>
</section>
</dd></dl>

</section>
<section id="add-code">
<h2>add_code<a class="headerlink" href="#add-code" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="phi_3_vision_mlx.add_code">
<span class="sig-prename descclassname"><span class="pre">phi_3_vision_mlx.</span></span><span class="sig-name descname"><span class="pre">add_code</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">codes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#phi_3_vision_mlx.add_code" title="Link to this definition">¶</a></dt>
<dd><p>Append Python code blocks to a given prompt.</p>
<section id="id33">
<h3>Parameters:<a class="headerlink" href="#id33" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>prompt<span class="classifier">str</span></dt><dd><p>The original prompt text.</p>
</dd>
<dt>codes<span class="classifier">list of str or None</span></dt><dd><p>A list of Python code strings to be appended to the prompt.</p>
</dd>
</dl>
</section>
<section id="id34">
<h3>Returns:<a class="headerlink" href="#id34" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>str or list of str</dt><dd><p>If codes is None, returns the original prompt.
Otherwise, returns a list of strings, each containing the original prompt
followed by a Python code block.</p>
</dd>
</dl>
</section>
</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &#169;2024, Josef Albers.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/module.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/JosefAlbers/Phi-3-Vision-MLX" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>